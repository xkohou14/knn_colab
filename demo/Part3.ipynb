{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#  Training with customdataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pathlib\n",
    "from transformations import Compose, AlbuSeg2d, DenseTarget \n",
    "from transformations import MoveAxis, Normalize01, Resize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from customdatasets import SegmentationDataSet\n",
    "import torch\n",
    "from unet import UNet\n",
    "from trainer import Trainer\n",
    "from torch.utils.data import DataLoader\n",
    "import albumentations\n",
    "from catalyst.contrib.nn import DiceLoss, RAdam, Lookahead, OneCycleLRWithWarmup\n",
    "\n",
    "# root directory\n",
    "root = pathlib.Path.cwd() / 'Carvana'\n",
    "def get_filenames_of_path(path: pathlib.Path, ext: str = '*'):\n",
    "    \"\"\"Returns a list of files in a directory/path. Uses pathlib.\"\"\"\n",
    "    filenames = [file for file in path.glob(ext) if file.is_file()]\n",
    "    return filenames\n",
    "\n",
    "# input and target files\n",
    "inputs = get_filenames_of_path(root / 'Input')\n",
    "targets = get_filenames_of_path(root / 'Target')\n",
    "\n",
    "# training transformations and augmentations\n",
    "transforms_training = Compose([\n",
    "    Resize(input_size=(128, 128, 3), target_size=(128, 128)),\n",
    "    AlbuSeg2d(albu=albumentations.HorizontalFlip(p=0.5)),\n",
    "    DenseTarget(),\n",
    "    MoveAxis(),\n",
    "    Normalize01()\n",
    "])\n",
    "\n",
    "# validation transformations\n",
    "transforms_validation = Compose([\n",
    "    Resize(input_size=(128, 128, 3), target_size=(128, 128)),\n",
    "    DenseTarget(),\n",
    "    MoveAxis(),\n",
    "    Normalize01()\n",
    "])\n",
    "\n",
    "\n",
    "# random seed\n",
    "random_seed = 42\n",
    "\n",
    "# split dataset into training set and validation set\n",
    "train_size = 0.8  # 80:20 split\n",
    "\n",
    "inputs_train, inputs_valid = train_test_split(\n",
    "    inputs,\n",
    "    random_state=random_seed,\n",
    "    train_size=train_size,\n",
    "    shuffle=True)\n",
    "\n",
    "targets_train, targets_valid = train_test_split(\n",
    "    targets,\n",
    "    random_state=random_seed,\n",
    "    train_size=train_size,\n",
    "    shuffle=True)\n",
    "\n",
    "# inputs_train, inputs_valid = inputs[:80], inputs[80:]\n",
    "# targets_train, targets_valid = targets[:80], targets[:80]\n",
    "\n",
    "# dataset training\n",
    "dataset_train = SegmentationDataSet(inputs=inputs_train,\n",
    "                                    targets=targets_train,\n",
    "                                    transform=transforms_training)\n",
    "\n",
    "# dataset validation\n",
    "dataset_valid = SegmentationDataSet(inputs=inputs_valid,\n",
    "                                    targets=targets_valid,\n",
    "                                    transform=transforms_validation)\n",
    "\n",
    "# dataloader training\n",
    "dataloader_training = DataLoader(dataset=dataset_train,\n",
    "                                 batch_size=2,\n",
    "                                 shuffle=True)\n",
    "\n",
    "# dataloader validation\n",
    "dataloader_validation = DataLoader(dataset=dataset_valid,\n",
    "                                   batch_size=2,\n",
    "                                   shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%gui qt\n",
    "# from visual import Input_Target_Pair_Generator\n",
    "# from visual import show_input_target_pair_napari\n",
    "#\n",
    "# gen_t = Input_Target_Pair_Generator(dataloader_training, rgb=True)\n",
    "# gen_v = Input_Target_Pair_Generator(dataloader_validation, rgb=True)\n",
    "# show_input_target_pair_napari(gen_t, gen_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Progress:   0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "69c30f7a40c042449d8e5d429e98ee5a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training:   0%|          | 0/183 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2365c9707f414c298abaec9e097188ec"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "only batches of spatial targets supported (3D tensors) but got targets of dimension: 4",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-7-7d09057abaf8>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     34\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     35\u001B[0m \u001B[1;31m# start training\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 36\u001B[1;33m \u001B[0mtraining_losses\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalidation_losses\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlr_rates\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtrainer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrun_trainer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     37\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\pokusKNN\\PyTorch-2D-3D-UNet-Tutorial\\trainer.py\u001B[0m in \u001B[0;36mrun_trainer\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     45\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     46\u001B[0m             \u001B[1;34m\"\"\"Training block\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 47\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_train\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     48\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     49\u001B[0m             \u001B[1;34m\"\"\"Validation block\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\pokusKNN\\PyTorch-2D-3D-UNet-Tutorial\\trainer.py\u001B[0m in \u001B[0;36m_train\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     75\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moptimizer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mzero_grad\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# zerograd the parameters\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     76\u001B[0m             \u001B[0mout\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# one forward pass\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 77\u001B[1;33m             \u001B[0mloss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcriterion\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mout\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtarget\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# calculate loss\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     78\u001B[0m             \u001B[0mloss_value\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mloss\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mitem\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     79\u001B[0m             \u001B[0mtrain_losses\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mloss_value\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\pokusknn\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m    887\u001B[0m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    888\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 889\u001B[1;33m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    890\u001B[0m         for hook in itertools.chain(\n\u001B[0;32m    891\u001B[0m                 \u001B[0m_global_forward_hooks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\pokusknn\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, input, target)\u001B[0m\n\u001B[0;32m    214\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtarget\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[0mTensor\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    215\u001B[0m         \u001B[1;32massert\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mweight\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mweight\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mTensor\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 216\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mF\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnll_loss\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtarget\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mweight\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mignore_index\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mignore_index\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mreduction\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreduction\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    217\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    218\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\pokusknn\\venv\\lib\\site-packages\\torch\\nn\\functional.py\u001B[0m in \u001B[0;36mnll_loss\u001B[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001B[0m\n\u001B[0;32m   2385\u001B[0m         \u001B[0mret\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_C\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_nn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnll_loss\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtarget\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_Reduction\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_enum\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mreduction\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mignore_index\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2386\u001B[0m     \u001B[1;32melif\u001B[0m \u001B[0mdim\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;36m4\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2387\u001B[1;33m         \u001B[0mret\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_C\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_nn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnll_loss2d\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtarget\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_Reduction\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_enum\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mreduction\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mignore_index\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2388\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2389\u001B[0m         \u001B[1;31m# dim == 3 or dim > 4\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: only batches of spatial targets supported (3D tensors) but got targets of dimension: 4"
     ]
    }
   ],
   "source": [
    "# device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# model\n",
    "model = UNet(in_channels=3,\n",
    "             out_channels=2,\n",
    "             n_blocks=4,\n",
    "             start_filters=32,\n",
    "             activation='relu',\n",
    "             normalization='batch',\n",
    "             conv_mode='same',\n",
    "             dim=2).to(device)\n",
    "\n",
    "# criterion\n",
    "criterion = torch.nn.NLLLoss()\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# trainer\n",
    "trainer = Trainer(model=model,\n",
    "                  device=device,\n",
    "                  criterion=criterion,\n",
    "                  optimizer=optimizer,\n",
    "                  training_DataLoader=dataloader_training,\n",
    "                  validation_DataLoader=dataloader_validation,\n",
    "                  lr_scheduler=None,\n",
    "                  epochs=4,\n",
    "                  epoch=0,\n",
    "                  notebook=True)\n",
    "\n",
    "# start training\n",
    "training_losses, validation_losses, lr_rates = trainer.run_trainer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with customdataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Caching:   0%|          | 0/366 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "da3e3cf3a4604ee6b480ff67394e0649"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Caching:   0%|          | 0/92 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "95f8950df1b0413a89ae4cf0bb0269f0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = shape: torch.Size([2, 3, 128, 128]); type: torch.float32\n",
      "x = min: 0.0; max: 1.0\n",
      "y = shape: torch.Size([2, 128, 128, 3]); class: tensor([0, 1, 2, 3, 4, 5]); type: torch.int64\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pathlib\n",
    "from transformations import Compose, AlbuSeg2d, DenseTarget \n",
    "from transformations import MoveAxis, Normalize01, Resize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from customdatasets2 import SegmentationDataSet\n",
    "import torch\n",
    "from unet import UNet\n",
    "from trainer import Trainer\n",
    "from torch.utils.data import DataLoader\n",
    "import albumentations\n",
    "\n",
    "# root directory\n",
    "root = pathlib.Path.cwd() / 'Carvana'\n",
    "def get_filenames_of_path(path: pathlib.Path, ext: str = '*'):\n",
    "    \"\"\"Returns a list of files in a directory/path. Uses pathlib.\"\"\"\n",
    "    filenames = [file for file in path.glob(ext) if file.is_file()]\n",
    "    return filenames\n",
    "\n",
    "# input and target files\n",
    "inputs = get_filenames_of_path(root / 'Input')\n",
    "targets = get_filenames_of_path(root / 'Target')\n",
    "\n",
    "# pre-transformations\n",
    "pre_transforms = Compose([\n",
    "    Resize(input_size=(128, 128, 3), target_size=(128, 128)),\n",
    "])\n",
    "# training transformations and augmentations\n",
    "transforms_training = Compose([\n",
    "    AlbuSeg2d(albu=albumentations.HorizontalFlip(p=0.5)),\n",
    "    DenseTarget(),\n",
    "    MoveAxis(),\n",
    "    Normalize01()\n",
    "])\n",
    "# validation transformations\n",
    "transforms_validation = Compose([\n",
    "    Resize(input_size=(128, 128, 3), target_size=(128, 128)),\n",
    "    DenseTarget(),\n",
    "    MoveAxis(),\n",
    "    Normalize01()\n",
    "])\n",
    "# random seed\n",
    "random_seed = 42\n",
    "\n",
    "# split dataset into training set and validation set\n",
    "train_size = 0.8  # 80:20 split\n",
    "\n",
    "inputs_train, inputs_valid = train_test_split(\n",
    "    inputs,\n",
    "    random_state=random_seed,\n",
    "    train_size=train_size,\n",
    "    shuffle=True)\n",
    "\n",
    "targets_train, targets_valid = train_test_split(\n",
    "    targets,\n",
    "    random_state=random_seed,\n",
    "    train_size=train_size,\n",
    "    shuffle=True)\n",
    "\n",
    "# inputs_train, inputs_valid = inputs[:80], inputs[80:]\n",
    "# targets_train, targets_valid = targets[:80], targets[:80]\n",
    "\n",
    "# dataset training\n",
    "dataset_train = SegmentationDataSet(inputs=inputs_train,\n",
    "                                    targets=targets_train,\n",
    "                                    transform=transforms_training,\n",
    "                                    use_cache=True,\n",
    "                                    pre_transform=pre_transforms)\n",
    "\n",
    "# dataset validation\n",
    "dataset_valid = SegmentationDataSet(inputs=inputs_valid,\n",
    "                                    targets=targets_valid,\n",
    "                                    transform=transforms_validation,\n",
    "                                    use_cache=True,\n",
    "                                    pre_transform=pre_transforms)\n",
    "\n",
    "# dataloader training\n",
    "dataloader_training = DataLoader(dataset=dataset_train,\n",
    "                                 batch_size=2,\n",
    "                                 shuffle=True)\n",
    "\n",
    "# dataloader validation\n",
    "dataloader_validation = DataLoader(dataset=dataset_valid,\n",
    "                                   batch_size=2,\n",
    "                                   shuffle=True)\n",
    "\n",
    "x, y = next(iter(dataloader_training))\n",
    "\n",
    "print(f'x = shape: {x.shape}; type: {x.dtype}')\n",
    "print(f'x = min: {x.min()}; max: {x.max()}')\n",
    "print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Viewer(axes=Axes(visible=False, labels=True, colored=True, dashed=False, arrows=True), camera=Camera(center=(0.0, 63.50000000000001, 63.50000000000001), zoom=3.822440944881889, angles=(0.0, 0.0, 90.0), interactive=True), cursor=Cursor(position=(0.0, 0.0, 0.0), scaled=True, size=10, style='standard'), dims=Dims(ndim=3, ndisplay=2, last_used=2, range=((0.0, 127.0, 1.0), (0.0, 127.0, 1.0), (0.0, 127.0, 1.0)), current_step=(0, 0, 0), order=(0, 1, 2), axis_labels=('0', '1', '2')), grid=GridCanvas(enabled=False, stride=1, shape=(-1, -1)), layers=[<Image layer 'input_training' at 0x1b732eb36d0>, <Labels layer 'target_training' at 0x1b7330f78b0>], scale_bar=ScaleBar(visible=False, colored=False, ticks=True, position='bottom_right'), active_layer=<Labels layer 'target_training' at 0x1b7330f78b0>, help='enter paint or fill mode to edit labels', status='target_training [0 0 0]: 0', theme='dark', title='napari', mouse_move_callbacks=[], mouse_drag_callbacks=[], mouse_wheel_callbacks=[<function dims_scroll at 0x000001B72FE51790>], _persisted_mouse_event={}, _mouse_drag_gen={}, _mouse_wheel_gen={}, keymap={'T': <function show_input_target_pair_napari.<locals>.next_batch_training at 0x000001B7371174C0>, 'V': <function show_input_target_pair_napari.<locals>.next_batch_validation at 0x000001B7371175E0>})"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%gui qt\n",
    "from visual import Input_Target_Pair_Generator\n",
    "from visual import show_input_target_pair_napari\n",
    "\n",
    "gen_t = Input_Target_Pair_Generator(dataloader_training, rgb=True)\n",
    "gen_v = Input_Target_Pair_Generator(dataloader_validation, rgb=True)\n",
    "show_input_target_pair_napari(gen_t, gen_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Progress:   0%|          | 0/10 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a8d7babbc44c473b81e3efc74392ab82"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training:   0%|          | 0/183 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6ae70f4a34d84e7c9a70ac90d8a1c62a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AssertionError",
     "evalue": "targets(shape torch.Size([2, 128, 128, 3])) and outputs(shape torch.Size([2, 2, 128, 128])) must have the same shape",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-12-702b06370302>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     36\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     37\u001B[0m \u001B[1;31m# start training\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 38\u001B[1;33m \u001B[0mtraining_losses\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalidation_losses\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlr_rates\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtrainer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrun_trainer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     39\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\pokusKNN\\PyTorch-2D-3D-UNet-Tutorial\\trainer.py\u001B[0m in \u001B[0;36mrun_trainer\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     45\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     46\u001B[0m             \u001B[1;34m\"\"\"Training block\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 47\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_train\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     48\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     49\u001B[0m             \u001B[1;34m\"\"\"Validation block\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\pokusKNN\\PyTorch-2D-3D-UNet-Tutorial\\trainer.py\u001B[0m in \u001B[0;36m_train\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     75\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moptimizer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mzero_grad\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# zerograd the parameters\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     76\u001B[0m             \u001B[0mout\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# one forward pass\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 77\u001B[1;33m             \u001B[0mloss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcriterion\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mout\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtarget\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# calculate loss\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     78\u001B[0m             \u001B[0mloss_value\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mloss\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mitem\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     79\u001B[0m             \u001B[0mtrain_losses\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mloss_value\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\pokusknn\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m    887\u001B[0m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    888\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 889\u001B[1;33m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    890\u001B[0m         for hook in itertools.chain(\n\u001B[0;32m    891\u001B[0m                 \u001B[0m_global_forward_hooks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\pokusknn\\venv\\lib\\site-packages\\catalyst\\contrib\\nn\\criterion\\dice.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, outputs, targets)\u001B[0m\n\u001B[0;32m     43\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moutputs\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mTensor\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtargets\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mTensor\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mTensor\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     44\u001B[0m         \u001B[1;34m\"\"\"Calculates loss between ``logits`` and ``target`` tensors.\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 45\u001B[1;33m         \u001B[0mdice_score\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mloss_fn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0moutputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtargets\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     46\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[1;36m1\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mdice_score\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     47\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\pokusknn\\venv\\lib\\site-packages\\catalyst\\metrics\\functional\\_segmentation.py\u001B[0m in \u001B[0;36mdice\u001B[1;34m(outputs, targets, class_dim, threshold, mode, weights, eps)\u001B[0m\n\u001B[0;32m    288\u001B[0m     \"\"\"\n\u001B[0;32m    289\u001B[0m     \u001B[0mmetric_fn\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpartial\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0m_dice\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0meps\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0meps\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 290\u001B[1;33m     score = _get_region_based_metrics(\n\u001B[0m\u001B[0;32m    291\u001B[0m         \u001B[0moutputs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0moutputs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    292\u001B[0m         \u001B[0mtargets\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtargets\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\pokusknn\\venv\\lib\\site-packages\\catalyst\\metrics\\functional\\_segmentation.py\u001B[0m in \u001B[0;36m_get_region_based_metrics\u001B[1;34m(outputs, targets, metric_fn, class_dim, threshold, mode, weights)\u001B[0m\n\u001B[0;32m    109\u001B[0m     \"\"\"\n\u001B[0;32m    110\u001B[0m     \u001B[1;32massert\u001B[0m \u001B[0mmode\u001B[0m \u001B[1;32min\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;34m\"per-class\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"micro\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"macro\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"weighted\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 111\u001B[1;33m     segmentation_stats = get_segmentation_statistics(\n\u001B[0m\u001B[0;32m    112\u001B[0m         \u001B[0moutputs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0moutputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtargets\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtargets\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mclass_dim\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mclass_dim\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mthreshold\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mthreshold\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    113\u001B[0m     )\n",
      "\u001B[1;32md:\\pokusknn\\venv\\lib\\site-packages\\catalyst\\metrics\\functional\\_segmentation.py\u001B[0m in \u001B[0;36mget_segmentation_statistics\u001B[1;34m(outputs, targets, class_dim, threshold)\u001B[0m\n\u001B[0;32m     49\u001B[0m         tensor([16.,  8.,  0.,  0.,  0.,  4.]))\n\u001B[0;32m     50\u001B[0m     \"\"\"\n\u001B[1;32m---> 51\u001B[1;33m     assert outputs.shape == targets.shape, (\n\u001B[0m\u001B[0;32m     52\u001B[0m         \u001B[1;34mf\"targets(shape {targets.shape})\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     53\u001B[0m         \u001B[1;34mf\" and outputs(shape {outputs.shape}) must have the same shape\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mAssertionError\u001B[0m: targets(shape torch.Size([2, 128, 128, 3])) and outputs(shape torch.Size([2, 2, 128, 128])) must have the same shape"
     ]
    }
   ],
   "source": [
    "# device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# model\n",
    "model = UNet(in_channels=3,\n",
    "             out_channels=2,\n",
    "             n_blocks=4,\n",
    "             start_filters=32,\n",
    "             activation='relu',\n",
    "             normalization='batch',\n",
    "             conv_mode='same',\n",
    "             dim=2).to(device)\n",
    "\n",
    "# criterion\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "criterion = DiceLoss()\n",
    "\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# trainer\n",
    "trainer = Trainer(model=model,\n",
    "                  device=device,\n",
    "                  criterion=criterion,\n",
    "                  optimizer=optimizer,\n",
    "                  training_DataLoader=dataloader_training,\n",
    "                  validation_DataLoader=dataloader_validation,\n",
    "                  lr_scheduler=None,\n",
    "                  epochs=10,\n",
    "                  epoch=0,\n",
    "                  notebook=True)\n",
    "\n",
    "# start training\n",
    "training_losses, validation_losses, lr_rates = trainer.run_trainer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with customdataset 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pathlib\n",
    "from transformations import Compose, AlbuSeg2d, DenseTarget \n",
    "from transformations import MoveAxis, Normalize01, Resize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from customdatasets3 import SegmentationDataSet\n",
    "import torch\n",
    "from unet import UNet\n",
    "from trainer import Trainer\n",
    "from torch.utils.data import DataLoader\n",
    "import albumentations\n",
    "\n",
    "# root directory\n",
    "root = pathlib.Path.cwd() / 'Carvana'\n",
    "def get_filenames_of_path(path: pathlib.Path, ext: str = '*'):\n",
    "    \"\"\"Returns a list of files in a directory/path. Uses pathlib.\"\"\"\n",
    "    filenames = [file for file in path.glob(ext) if file.is_file()]\n",
    "    return filenames\n",
    "\n",
    "# input and target files\n",
    "inputs = get_filenames_of_path(root / 'Input')\n",
    "targets = get_filenames_of_path(root / 'Target')\n",
    "\n",
    "# pre-transformations\n",
    "pre_transforms = Compose([\n",
    "    Resize(input_size=(128, 128, 3), target_size=(128, 128)),\n",
    "])\n",
    "# training transformations and augmentations\n",
    "transforms_training = Compose([\n",
    "    Resize(input_size=(128, 128, 3), target_size=(128, 128)),\n",
    "    AlbuSeg2d(albu=albumentations.HorizontalFlip(p=0.5)),\n",
    "    DenseTarget(),\n",
    "    MoveAxis(),\n",
    "    Normalize01()\n",
    "])\n",
    "# validation transformations\n",
    "transforms_validation = Compose([\n",
    "    DenseTarget(),\n",
    "    MoveAxis(),\n",
    "    Normalize01()\n",
    "])\n",
    "# random seed\n",
    "random_seed = 42\n",
    "\n",
    "# split dataset into training set and validation set\n",
    "train_size = 0.8  # 80:20 split\n",
    "\n",
    "inputs_train, inputs_valid = train_test_split(\n",
    "    inputs,\n",
    "    random_state=random_seed,\n",
    "    train_size=train_size,\n",
    "    shuffle=True)\n",
    "\n",
    "targets_train, targets_valid = train_test_split(\n",
    "    targets,\n",
    "    random_state=random_seed,\n",
    "    train_size=train_size,\n",
    "    shuffle=True)\n",
    "\n",
    "# inputs_train, inputs_valid = inputs[:80], inputs[80:]\n",
    "# targets_train, targets_valid = targets[:80], targets[:80]\n",
    "\n",
    "# dataset training\n",
    "dataset_train = SegmentationDataSet(inputs=inputs_train,\n",
    "                                    targets=targets_train,\n",
    "                                    transform=transforms_training,\n",
    "                                    use_cache=True,\n",
    "                                    pre_transform=pre_transforms)\n",
    "\n",
    "# dataset validation\n",
    "dataset_valid = SegmentationDataSet(inputs=inputs_valid,\n",
    "                                    targets=targets_valid,\n",
    "                                    transform=transforms_validation,\n",
    "                                    use_cache=True,\n",
    "                                    pre_transform=pre_transforms)\n",
    "\n",
    "# dataloader training\n",
    "dataloader_training = DataLoader(dataset=dataset_train,\n",
    "                                 batch_size=2,\n",
    "                                 shuffle=True)\n",
    "\n",
    "# dataloader validation\n",
    "dataloader_validation = DataLoader(dataset=dataset_valid,\n",
    "                                   batch_size=2,\n",
    "                                   shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Progress:   0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ab284049f833444abe18bd599040863c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training:   0%|          | 0/183 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "98af5458cd964788b39a579a02520dc5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AssertionError",
     "evalue": "targets(shape torch.Size([2, 128, 128, 3])) and outputs(shape torch.Size([2, 2, 128, 128])) must have the same shape",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-6-a1ca895a75f2>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     38\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     39\u001B[0m \u001B[1;31m# start training\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 40\u001B[1;33m \u001B[0mtraining_losses\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalidation_losses\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlr_rates\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtrainer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrun_trainer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     41\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\pokusKNN\\PyTorch-2D-3D-UNet-Tutorial\\trainer.py\u001B[0m in \u001B[0;36mrun_trainer\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     45\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     46\u001B[0m             \u001B[1;34m\"\"\"Training block\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 47\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_train\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     48\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     49\u001B[0m             \u001B[1;34m\"\"\"Validation block\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\pokusKNN\\PyTorch-2D-3D-UNet-Tutorial\\trainer.py\u001B[0m in \u001B[0;36m_train\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     75\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moptimizer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mzero_grad\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# zerograd the parameters\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     76\u001B[0m             \u001B[0mout\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# one forward pass\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 77\u001B[1;33m             \u001B[0mloss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcriterion\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mout\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtarget\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# calculate loss\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     78\u001B[0m             \u001B[0mloss_value\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mloss\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mitem\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     79\u001B[0m             \u001B[0mtrain_losses\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mloss_value\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\pokusknn\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m    887\u001B[0m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    888\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 889\u001B[1;33m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    890\u001B[0m         for hook in itertools.chain(\n\u001B[0;32m    891\u001B[0m                 \u001B[0m_global_forward_hooks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\pokusknn\\venv\\lib\\site-packages\\catalyst\\contrib\\nn\\criterion\\dice.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, outputs, targets)\u001B[0m\n\u001B[0;32m     43\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moutputs\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mTensor\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtargets\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mTensor\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mTensor\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     44\u001B[0m         \u001B[1;34m\"\"\"Calculates loss between ``logits`` and ``target`` tensors.\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 45\u001B[1;33m         \u001B[0mdice_score\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mloss_fn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0moutputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtargets\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     46\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[1;36m1\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mdice_score\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     47\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\pokusknn\\venv\\lib\\site-packages\\catalyst\\metrics\\functional\\_segmentation.py\u001B[0m in \u001B[0;36mdice\u001B[1;34m(outputs, targets, class_dim, threshold, mode, weights, eps)\u001B[0m\n\u001B[0;32m    288\u001B[0m     \"\"\"\n\u001B[0;32m    289\u001B[0m     \u001B[0mmetric_fn\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpartial\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0m_dice\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0meps\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0meps\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 290\u001B[1;33m     score = _get_region_based_metrics(\n\u001B[0m\u001B[0;32m    291\u001B[0m         \u001B[0moutputs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0moutputs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    292\u001B[0m         \u001B[0mtargets\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtargets\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\pokusknn\\venv\\lib\\site-packages\\catalyst\\metrics\\functional\\_segmentation.py\u001B[0m in \u001B[0;36m_get_region_based_metrics\u001B[1;34m(outputs, targets, metric_fn, class_dim, threshold, mode, weights)\u001B[0m\n\u001B[0;32m    109\u001B[0m     \"\"\"\n\u001B[0;32m    110\u001B[0m     \u001B[1;32massert\u001B[0m \u001B[0mmode\u001B[0m \u001B[1;32min\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;34m\"per-class\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"micro\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"macro\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"weighted\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 111\u001B[1;33m     segmentation_stats = get_segmentation_statistics(\n\u001B[0m\u001B[0;32m    112\u001B[0m         \u001B[0moutputs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0moutputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtargets\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtargets\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mclass_dim\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mclass_dim\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mthreshold\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mthreshold\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    113\u001B[0m     )\n",
      "\u001B[1;32md:\\pokusknn\\venv\\lib\\site-packages\\catalyst\\metrics\\functional\\_segmentation.py\u001B[0m in \u001B[0;36mget_segmentation_statistics\u001B[1;34m(outputs, targets, class_dim, threshold)\u001B[0m\n\u001B[0;32m     49\u001B[0m         tensor([16.,  8.,  0.,  0.,  0.,  4.]))\n\u001B[0;32m     50\u001B[0m     \"\"\"\n\u001B[1;32m---> 51\u001B[1;33m     assert outputs.shape == targets.shape, (\n\u001B[0m\u001B[0;32m     52\u001B[0m         \u001B[1;34mf\"targets(shape {targets.shape})\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     53\u001B[0m         \u001B[1;34mf\" and outputs(shape {outputs.shape}) must have the same shape\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mAssertionError\u001B[0m: targets(shape torch.Size([2, 128, 128, 3])) and outputs(shape torch.Size([2, 2, 128, 128])) must have the same shape"
     ]
    }
   ],
   "source": [
    "\n",
    "# device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device =torch.device('cpu')\n",
    "\n",
    "# model\n",
    "model = UNet(in_channels=3,\n",
    "             out_channels=2,\n",
    "             n_blocks=4,\n",
    "             start_filters=32,\n",
    "             activation='relu',\n",
    "             normalization='batch',\n",
    "             conv_mode='same',\n",
    "             dim=2).to(device)\n",
    "\n",
    "# criterion\n",
    "#criterion = torch.nn.CrossEntropyLoss()\n",
    "criterion = DiceLoss()\n",
    "# criterion = torch.\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# trainer\n",
    "trainer = Trainer(model=model,\n",
    "                  device=device,\n",
    "                  criterion=criterion,\n",
    "                  optimizer=optimizer,\n",
    "                  training_DataLoader=dataloader_training,\n",
    "                  validation_DataLoader=dataloader_validation,\n",
    "                  lr_scheduler=None,\n",
    "                  epochs=100,\n",
    "                  epoch=0,\n",
    "                  notebook=True)\n",
    "\n",
    "# start training\n",
    "training_losses, validation_losses, lr_rates = trainer.run_trainer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# save the model\n",
    "model_name =  'carvana_model2.pt'\n",
    "torch.save(model.state_dict(), pathlib.Path.cwd() / model_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Learning rate finder"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# save the model\n",
    "model_name =  'carvana_model2.pt'\n",
    "torch.save(model.state_dict(), pathlib.Path.cwd() / model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning rate finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "model_name =  'carvana_model2.pt'\n",
    "torch.save(model.state_dict(), pathlib.Path.cwd() / model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning rate finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# model\n",
    "model = UNet(in_channels=3,\n",
    "             out_channels=2,\n",
    "             n_blocks=4,\n",
    "             start_filters=32,\n",
    "             activation='relu',\n",
    "             normalization='batch',\n",
    "             conv_mode='same',\n",
    "             dim=2).to(device)\n",
    "\n",
    "# criterion\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lr_rate_finder import LearningRateFinder\n",
    "lrf = LearningRateFinder(model, criterion, optimizer, device)\n",
    "lrf.fit(dataloader_training, steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrf.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visual import plot_training\n",
    "fig = plot_training(training_losses, validation_losses, lr_rates, gaussian=True, sigma=1, figsize=(10, 4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}